{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Transformations\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you will take a look at logarithmic transformations and when to apply them to features of a dataset. This will then become an effective technique you can use to improve the performance of linear regression models.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Determine if a log transformation would be useful for a specific model or set of data\n",
    "* Apply log transformations to independent and dependent variables in linear regression\n",
    "* Interpret the coefficients of variables that have been transformed using a log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Transformations\n",
    "\n",
    "Log transformations are one of several different techniques that fundamentally reshape the modeled relationship between the variables. Unlike linear transformations, we won't be able to \"go back\" to the initial or original linear coefficients, because what we are modeling is not the same relationship.\n",
    "\n",
    "The reason to apply this kind of transformation is that **you believe that the underlying relationship is not linear**. Then by applying these techniques, you may be able to model a linear relationship between the transformed variables, even though there wasn't a linear relationship between the raw, un-transformed variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Functions\n",
    "\n",
    "While we typically use the shorthand of \"log\", the full name of the function we are applying is the ***logarithm***. Logarithmic functions are the inverse of exponential functions. The particular logarithm we typically use is the natural logarithm, which is the opposite of an exponential function of the mathematical constant $e$ (also known as Euler's number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural exponential function $e^x$ means taking each value of a variable and returning $e$ to the power of $x$. It looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original x\n",
    "x = np.arange(0, 10, 0.5)\n",
    "# natural exponential function applied to x\n",
    "e_x = np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(7,3))\n",
    "\n",
    "ax1.scatter(x, x)\n",
    "ax1.set_ylabel(\"$x$\")\n",
    "ax2.scatter(x, e_x)\n",
    "ax2.set_ylabel(\"$e^x$\")\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the natural logarithm is the **inverse** of $e^x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# natural log of natural exponent of x\n",
    "ln_e_x = np.log(e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAADQCAYAAAAasZepAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiJklEQVR4nO3df7DcdXno8XdCQnKkCalXKSbjFPXePvdUwR+0Qgk/Mv5KQaoMc+l1uN7SWhG4WNDpxfIj3I4tDvijWLle0EYdQfTaCkKVFnFGlBtiLXNPYxumy2PBOp2J8ZaqIQFyAgnn/rG7ZnOyZ8/Jyfnu97O779cM49nvfs7us8f97PPku5/P8100NTWFJEmSpKbFdQcgSZIklcQCWZIkSepggSxJkiR1sECWJEmSOlggS5IkSR0skCVJkqQOS+oOQNLCi4iTgA9m5rqOY+cDv5eZv9a6fSFwEbAXuC4z74mIMeB24BhgF3BBZj4eEScDH2uN/Xpmvr+vL0iSpD7yDLI0ZCLifcCngOUdx14F/C6wqHX7WOAyYC2wHrg+IpYBlwBbM/M04DZgQ+shPgGcD5wKnBQRr+nLi5EkqQYWyNLweQw4t30jIv4dcAPwno4xrwU2Z+aezHwCeBQ4gWYB/LXWmHuBN0TESmBZZj6WmVPAfcDrK38VkiTVpLYlFhMTE17CTyPhxBNPXNTP58vMOyPiOICIOAL4NPBeYHfHsJXAEx23dwFHTzveeWzntLEvnf68zmmNin7P6bo4pzUqus3pWtcgn3jiiT3vbzQajI+P9yma3kqKBcqKp6RYoKx4JiYm6g7hROA/ALfQXHLxyxHxp8D9wIqOcSuAHTQL4RU9jnUeP/jJeszpkv5/AePppaRYoKx4CpjTfeWcnp+SYoGy4ikpFph5TrtJTxpimfkQ8HKA1lnlL2bme1prkD8QEcuBZcA48DCwGTgLeAg4E9iUmTsj4pmIeBnwfZprlt2kJ0kaWq5BlkZQZv4IuAnYRPNs8jWZOUnzTPPLI+JB4F3sL4QvBj5Ps3Dekpl/2/+oJUnqD88gS0MoM38AnNzrWGZuBDZOG/M0cF6Xx/vO9MeTJGlYWSBL83D3lm18+L7khzt2s3rVGFesD8559Zq6w5I0D85nabgsxJy2QJYO0d1btnHVl7ey+9l9AGzbsZurvrwVwKQqDRjnszRcFmpOuwZZOkQfvi9/NvHadj+7jw/flzVFJGm+nM/ScFmoOW2BLB2iH+7YfUjHJZXL+SwNl4Wa0xbI0iFavWrskI5LKpfzWRouCzWnLZClQ3TF+mBs6REHHBtbegRXrI+aIpI0X85nabgs1Jx2k550iNqL/N31Lg0+57M0XBZqTlsgS/NwzqvXmEClIeF8lobLQsxpC2RpGnuiSpJUpn7laAtkqYM9USVJKlM/c7Sb9KQO9kSVJKlM/czRFshSB3uiSpJUpn7maAtkqYM9USVJKlM/c7QFstTBnqiSJJWpnznaTXpSB3uiSpJUpn7maAtkaRp7okqSVKZ+5WiXWEiSJEkdPIOskTIqFwGJiJOAD2bmuoh4FfA/gX3AHuC3MvP/RcSFwEXAXuC6zLwnIsaA24FjgF3ABZn5eEScDHysNfbrmfn+/r8qSdIwKylHewZZI6PdYHzbjt1Msb/B+N1bttUd2oKKiPcBnwKWtw59DPi9zFwHfBn4g4g4FrgMWAusB66PiGXAJcDWzDwNuA3Y0HqMTwDnA6cCJ0XEa/r0ciRJI6C0HO0ZZI2MXg3Gh+ws8mPAucDnWrfflpnbWz8vASaB1wKbM3MPsCciHgVOoFkAf6g19l7g2ohYCSzLzMcAIuI+4PXA301/4kajMWNQk5OTPe/vN+OZWUmxQHnxSFp4peVoC2SNjFG5CEhm3hkRx3Xc3g4QEacA7wZOp3nW+ImOX9sFHA2s7DjeeWzntLEv7fbc4+PjM8bVaDR63t9vxjOzkmKBsuKZmJioOwRpKJWWo11ioZExyhcBiYj/THOZxJsz83GaBe+KjiErgB3Tjnc71nlckqQFUVqOtkDWyBjVi4BExNtpnjlel5nfbx1+CDgtIpZHxNHAOPAwsBk4qzXmTGBTZu4EnomIl0XEIppnnzf19UVIkoZaaTnaJRYaGaN4EZCIOAK4CfgX4MsRAfBAZv5hRNxEs9BdDFyTmZMRcQtwa0Q8CDxDc2MewMXA54EjaHax+Ns+vxRJ0hArLUdbIGukjMpFQDLzB8DJrZvPn2HMRmDjtGNPA+d1GfudjseTJGnBlZSjLZA1NA7sn7h96M8OS5I0KAYtR1dWIEfEUuBW4DiaFyi4MDMfqer5NNra/RPbLWLa/ROBoiegJNXBHK1+GsQcXeUmvbOAJZl5CvBHwAcqfC6NuF79EyVJBzFHq28GMUdXucTie8CSiFhMs4/qs9MHzNb4vaTm8CXFAmXFU0Isvfon1h2bJBVo1hwNXvxnvkqKBeqPZxBzdJUF8pM0v7p5BHgBcPb0AbM1fi+pOXxJsUBZ8ZQQy+pV29nWZQKuXjVWa2xeVEBSoWbN0eDFf+arpFig/nhKzdEwc56uconFe4H7MvOXgFfSbB21vMLn0wgrrX+iJBXOHK2+GcQcXeUZ5J+y/yubnwBLafZQlRZcaf0TJalw5mj1zSDm6CoL5I8Cn4mITcCRwNWZ+VSFz6cR1+6fWPdXSZI0AMzR6qtBy9GVFciZ+STwm1U9viRJmh9ztNSbFwrRQDiwwXj5X81IkjRKhi1PWyCreIPYYFySpFExjHm6yi4W0oIYxAbjkiSNimHM0xbIKl6vBuOSJKlew5inLZBVvNWrxg7puCRJ6p9hzNMWyCreIDYYlyRpVAxjnnaTnoo3iA3GJUkaFcOYpy2QNRDaDcY1NxFxEvDBzFwXEf8e+CwwBTwMXJqZz0XEhcBFwF7gusy8JyLGgNuBY4BdwAWZ+XhEnAx8rDX265n5/v6/KklSqYYtT7vEQrW7e8s21t5wPy+58q9Ye8P93L1lW90hDbSIeB/wKWB569CNwIbMPA1YBLw1Io4FLgPWAuuB6yNiGXAJsLU19jZgQ+sxPgGcD5wKnBQRr+nX65Ek1WsU87QFsmrV7p24bcduptjfO3EUJl+FHgPO7bh9IvBA6+d7gTcArwU2Z+aezHwCeBQ4gWYB/LXOsRGxEliWmY9l5hRwH/D66l+GJKluo5qnXWKhWvXqnThMX9X0U2beGRHHdRxa1Cpsobls4mhgJfBEx5huxzuP7Zw29qXdnrvRaMwY1+TkZM/7+814ZlZSLFBePNIoGdU8bYGsWg1j78QCPdfx8wpgB82Cd8Usx2cbe5Dx8fEZg2g0Gj3v7zfjmVlJsUBZ8UxMTNQdgtRXo5qnXWKhWg1j78QCbYmIda2fzwQ2AQ8Bp0XE8og4GhinuYFvM3BW59jM3Ak8ExEvi4hFNNcsb+rnC5Ak1WNU87QFsmo1jL0TC/T7wPsj4m+AI4E7MvNHwE00C937gWsycxK4BXh5RDwIvAtod6u4GPg8zcJ6S2b+bZ9fgySpBqOap11ioVoNY+/EEmTmD4CTWz9/Dzijy5iNwMZpx54Gzusy9jvtx5MkjY5RzdMWyKrdsPVOlCRpmIxinnaJhSRJktTBM8iq1N1bto3c1zKSJA0K83R3FsiqTLu5eLt/Yru5OODkkySpZubpmbnEQpXp1VxckiTVyzw9MwtkVWZUm4tLkjQIzNMzs0BWZUa1ubgkSYPAPD0zC2RVZlSbi0uSNAjM0zNzk54qM6rNxSVJGgTm6ZlZIKtSo9hcXJKkQWGe7s4lFpIkSVKHSs8gR8RVwFuAI4GbM/PTVT6f+uvA5uLb/VpGkgaIOXr4mafnr7ICOSLWAacAa4HnAf+9qudS/9lcXJIGlzl6+JmnD0+VSyzWA1uBu4CvAvdU+FzqM5uLS9JAM0cPOfP04alyicULgF8EzgZeAnwlIv5jZk61BzQajZ4PMDk5OeuYfikpFqg/nl7Nxev+O9X9t5GkATBrjobeebq0z9qS4ikhllLzdAl/m7moskD+MfBIZj4DZERMAi8E/rU9YHx8vOcDNBqNWcf0S0mxQP3xrF61nW1dJt/qVWO1/53q/tt0mpiYqDsEaeQduA7TNlYts+Zo6J2nS/qshbLiKSGWUvN0CX+bTjPl6SoL5AeByyPiRuBFwFE0J6SGwBXr44C1TWBz8VJFxFLgVuA4YB9wIbAX+CwwBTwMXJqZz0XEhcBFrfuvy8x7ImIMuB04BtgFXJCZj/f7dUjz4TrMGZmjh5x5+vBUtgY5M+8BtgAP0VzfdGlm7uv9WxoU57x6DdefezxrVo2xCFizaozrzz1+1BNOqc4ClmTmKcAfAR8AbgQ2ZOZpwCLgrRFxLHAZzU0764HrI2IZcAmwtTX2NmBDDa9BmhfXYXZnjh5+5unDU2mbt8x8X5WPr3q1m4uX9nWJDvI9YElELAZWAs8CJwMPtO6/F3gTzbPLmzNzD7AnIh4FTgBOBT7UMfbaPsYuHZZe6zBHnTl6+Jmn588r6WlGrtsbGk/SXF7xCM2NOWcDp3dsxtkFHE2zeH6i4/e6HW8f68oNPfNXUjwlxQKHF88Lj1rCvz61t+vxkl7jfEXEUcCkZ39Hjzm6WhbI6sp1e0PlvcB9mXlVRLwYuJ/mhQHaVgA7gJ2tn3sdbx/ryg0981dSPCXFAocXz9Vnr+y6DvPqs1/B+Pihf5bVvfG29U3Q24D/AvwqsAdYFhGPA38N/Flm/lONIaoPzNHV81LT6sp1e0Plp+w/A/wTYCmwpXWhAIAzgU001yKeFhHLI+JoYJzmBr7NNNcxd46VBsIQrsP8JvAy4Crg2Mx8cWYeA5wGfAe4ISLeXmeAqp45unqeQVZXrtsbKh8FPhMRm2ieOb4a+L/Axog4EmgAd2Tmvoi4iWYBvBi4JjMnI+IW4NaIeBB4Bji/llchzVN7HeaQeENmPjv9YGb+BLgTuLPVuUZDzBxdPQtkdbV61diM/RM1WDLzSeA3u9x1RpexG4GN0449DZxXTXSSDtFzsw3oVkBruJijq+cSC3V1xfpgbOkRBxyzf6Ik1e7PIuJ5ABFxet3BqB7m6Op5Blldtb+OdIesJBXlfwCfjoi9wHeB/1NvOKqDObp6Fsia0ZCt25OkYfDHQAIvBf6i5lhUI3N0tSyQJUkaHO/LzH9r9T/+GPDOugOShpEF8oiywbgkDZ7M/LfWj6uBxRHxvzLz0jpj0sIzR9fPTXojqN1gfNuO3Uyxv8H43Vu21R2aJGluPgd8iWb/YyLiFRFxW70haSGYo8tggTyCbDAuSQNvcWbeC+wDyMyHgVfUG5IWgjm6DBbII8gG42WKiCNmHyVJAPwwIl4CTAFExCLAJrhDwBxdBgvkETRTI3EbjNfO/qaS5uo9NC/qc2xE/A7wRZqXhteAM0eXwQJ5BNlgvFjt/qafA3617mAklSszfwD8OnAZzZZvDwD/tc6YtDDM0WWYtYtFRPwp8N7MnKo+HPWDDcaLZX9TST1FxKJ2Ps7MvcAdrf+6jtHgMUeXYS5t3p4EvhIRb8vMpyLiTcAfZubaimNThWwwXiT7m0qazTcj4k7gLzPzX9oHI+JI4FTgAuCbwGfrCU8LwRxdv1kL5MzcEBHnA9+KiD3AU8CVlUemebN/4mCyv6mkOfh14B3A/25t0ttBc3PeYuDrwEcz87u1RadZmaMHw1yWWLweuJBmYfwi4Hcz014jhWr3T2y3iGn3TwScgIPjc8D7gQ9Cs78pzbPLv1VrVJJql5mTwM3AzRGxFHgBsDszd9QamObEHD045rJJ7xrg2sxcB/wn4M8j4nWVRqV5s3/iULC/qaRZZeazmbnd4nhwmKMHx1yWWLyu4+etEXEmcCdwSpWBaX7snzgU7G8qqaeI+CdgK/D3wHeBv291tlDBzNGDYy6b9A6Qmdtbyy5UoNWrxtjWZaLZP3GgvAf4FPv7m/46h9nfNCKuAt4CHEnz69kHaG7imWo99qWZ+VxEXAhcBOwFrsvMeyJiDLgdOAbYBVyQmY8fTjySDtsnaXa8+TFwJvD5iPhn4C7gjzPz2TqDU3fm6MExrz7Imek/dQpl/8TBt9D9TSNiHc1vfNYCZwAvBm4ENmTmacAi4K0RcWzrOdcC64HrI2IZcAmwtTX2NmDDfGORtGDenpn/LTM/npkX0+xgcT+wk+b8VoHM0YPjkM8gq2z2TxwOM/U3naf1NL+KvQtYCVxBc+PtA6377wXeRHPN8+bM3APsiYhHgRNoJt4PdYy9dgFiknR4noiIEzLzHwAy87sRcXJmXh4Rf1d3cOrOHD04LJCHkP0TNc0LgF8EzgZeAnyF5kbA9oUEdgFH0yyen+j4vW7H28e6ajQaMwYxOTnZ8/5+M56ZlRQLlBdPIS4Gbo+I79JcgxzAc637jqwpJs2BOXowWCBLw+/HwCOZ+QyQETFJc5lF2wqavVR3tn7udbx9rKvx8fEZg2g0Gj3v7zfjmVlJsUBZ8UxMTNQdAgCZ2YiI1wLn0vym51HgD1sXGvpircFJQ6DSAjkijgEmgDdm5iNVPteoOLDB+Ha/mtFcPAhcHhE30uxlfhTwjYhYl5nfornB55vAQ8AHImI5sAwYp7mBbzNwVuv+M4FNfX8Fkg4QEc8H3ktz8+w/Ardl5k9bd193CI9jnl5A5ujhMa9NenPRamD+ScANfQuk3WB8247dTLG/wfjdW7bVHZoKlpn3AFtoFrhfBS4Ffh94f0T8Dc2vY+/IzB8BN9EsgO8HrmldlOAW4OUR8SDwLpoXMZFUry/SXPL0VeB5wIOtM8pzZp5eWObo4VLlGeSPAJ8ArqrwOUZKrwbj/gtVvWTm+7ocPqPLuI3AxmnHngbOqyg0SfPzosxsb569JyL+HPgCcPIhPIZ5egGZo4dLJQVyRPw28Hhm3tfqv9rVbJsuStqYUUIsvRqM1xlbCX+bTqXFI0kV+Mm0Lhbfj4jnzfWXFyJPl/ZZW3c8peZoqP9v06mkWHqp6gzyO4CpiHgD8Crgtoh4S+sr3J+ZbdNFSRszSohl9artMzYYrzO2Ev42nUqKp5QNPZKGzruAOyNiE802ji8HHjuE3z/sPF3SZy3UH0+pORrq/9t0KikWmDlPV1IgZ+bp7Z8j4lvAxdMnnQ7dFeuDq7689YCvcGwwLkmjIyJuo9nW7bvA64B1NDfUbqG5t2BOzNMLzxw9XGzzNkBsMC5JI+9W4JXABa3/XUmzi8VS4DeAL9UX2mgzRw+XygvkzFxX9XOMknaD8dK+opAkVS8zvwF8o307IpYAv0yzWD6JeRTI5umFY44eHp5BLsiB/RP9l6ckzWbUPzdbl6X/h9Z/n6s5nKE26u+1UWOBXIh2/8T22qV2/0TACShJXfi5qX7xvTZ6KrtQiA5Nr/6JkqSD+bmpfvG9NnoskAvRq3+iJOlgfm6qX3yvjR4L5EKsXjV2SMcladT5ual+8b02eiyQC3HF+mBs6REHHLN/oiTNzM9N9YvvtdHjJr1C2D9Rkg6Nn5vqF99ro8cCuSDt/omSpLnxc1P94ntttLjEQpIkSergGeQ+scG4JEnlMk+rkwVyH9hgXJKkcpmnNZ1LLPrABuOSJJXLPK3pPIPcBzYYVwki4hhgAngjsBf4LDAFPAxcmpnPRcSFwEWt+6/LzHsiYgy4HTgG2AVckJmP1/ASJKkS5mlN5xnkPrDBuOoWEUuBTwLtT/sbgQ2ZeRqwCHhrRBwLXAasBdYD10fEMuASYGtr7G3Ahn7HL0lVMk9rOgvkPrDBuArwEeATwA9bt08EHmj9fC/wBuC1wObM3JOZTwCPAicApwJfmzZWkoaGeVrTucSiD2wwrjpFxG8Dj2fmfRFxVevwosycav28CzgaWAk80fGr3Y63j3XVaDRmjGNycrLn/f1mPDMrKRYoLx4NH/O0prNA7hMbjKtG7wCmIuINwKtoLpM4puP+FcAOYGfr517H28e6Gh8fnzGIRqPR8/5+M56ZlRQLlBXPxMRE3SGoIuZpdbJAXgD2TlTJMvP09s8R8S3gYuDDEbEuM78FnAl8E3gI+EBELAeWAeM0N/BtBs5q3X8msKmf8UvS4TJP61BZIB8meydqQP0+sDEijgQawB2ZuS8ibqJZAC8GrsnMyYi4Bbg1Ih4EngHOry1qSTpE5mnNhwXyYerVO9GJp9Jk5rqOm2d0uX8jsHHasaeB86qNTJKqYZ7WfNjF4jDZO1GSpHKZpzUfFsiHyd6JkiSVyzyt+bBAPkz2TpQkqVzmac2Ha5APk70TJUkql3la82GBvADsnShJC+/A1lzbLWo0b+ZpHSoLZElScWzNJalOlRTIEbEU+AxwHM0LDlyXmV+p4rmq5hkMSeo/W3NVyzwt9VbVJr23Az/OzNNoXnnr4xU9T6XaZzC27djNFPvPYNy9ZVvdoUnSULM1V+XM01IPVRXIXwKu7bi9t6LnqVSvMxiSpOrYmqty5mmph0qWWGTmkwARsQK4A9jQbVyj0ej5OJOTk7OOqVKvMxh1xgX1/206lRQLlBePpEN3xfo4YA0y2JprIS1Eni7hs7bUPF3C36ZTSfGUFEsvlW3Si4gXA3cBN2fmF7qNGR8f7/kYjUZj1jFVWr1qO9u6TL7Vq8ZqjQvq/9t0KikWKCueiYmJukOQBpKtuap3uHm6hM/aUvN0CX+bTiXFU1IsMHOermqT3i8AXwfenZnfqOI5+sEzGJJUn3ZrrtIS6jAwT0u9VXUG+Wrg54FrI6K9xunMzByo3RWewZAkDSnztNRDVWuQLwcur+Kx+80zGJKkYWOelnqrqouFJEmSNJBG+kp6BzYX92sZSZJKYp5WXUa2QPYyphoV3a6YBfwj8FlgCngYuDQzn4uIC4GLaPZEvS4z74mIMeB24BhgF3BBZj7e79chabSYp1WnkV1iYXNxjZBuV8y6EdjQOrYIeGtEHAtcBqwF1gPXR8Qy4BJga2vsbczQL1WSFpJ5WnUa2TPIXsZUI+RLNC8E0LYXOBF4oHX7XuBNwD5gc2buAfZExKPACcCpwIc6xnZefUuaF78612zM06rTyBbIq1eNzdhcXBomM1wx6yOZOdUasgs4GlgJPNHxq92Ot491VfpVtzoZz8yqjuX+7+/ipm//G3v2Nd+C23bs5g/u+Hu2/XAbr3vpir7HozKZp1WnkS2QbS6uUTL9ilkR8aGOu1cAO4CdrZ97HW8f66r0q251Mp6ZVR3LO//y/p8Vx2179k3xha1PcumbX9v3eA6FV8fsH/O06jSya5DPefUarj/3eNasGmMRsGbVGNefe7xf8WnodFwx6w8y8zOtw1siYl3r5zOBTcBDwGkRsTwijgbGaW7g2wycNW2sNG9+da65ME+rTiN7Bhn2NxeXhly3K2ZdDtwUEUcCDeCOzNwXETfRLIAXA9dk5mRE3ALcGhEPAs8A5/f/JWiY+NW55so8rboMdYHsJhCp5xWzzugydiOwcdqxp4HzqolOo8ivzgXmaJVtaAtk+ydKUpnan8EWR6PLHK3SDW2B3Kt/opNPkurlV+ejzRyt0g3tJj03gUiSVCZztEo3tGeQ3QQiSfVwbalmY45W6Yb2DPIV64OxpUcccMxNIJJUrfba0m07djPF/rWld2/ZVndoKog5WqUb2gLZ/omS1H+91pZKbeZolW5ol1iAm0Akqd9cW6q5MkerZEN7BlmS1H8zrSF1bamkQTKwZ5DdBCJJ/TfbZ68XARGYozX4BrJAtsG4JPXfXD57vQiIzNEaBgNZINtgXJL6b66fva4tHW3maA2DgSyQ3QQiSQvvwK/Ftx905tfPXs2F7xMNg4HcpOcmEElaWHPpX+xnr+bC94mGwUAWyDYYl6RDc/eWbay94X5ecuVfsfaG+w+6cMdc+hf72au58H2iYTCQSyzcBCJJ+83WMWAum6bm8rW4n72aC98nGgYDWSCDm0AkjY5eBfBcit+5bJpavWqMbV2K5Olfi/vZq7nwfaJBV1mBHBGLgZuBVwJ7gHdm5qNz+d3ZNopI6q+q5/NceqZWM6b8eGYrgOdS/M7l7LD9i0eLOVrqrco1yOcAyzPz14ArgT+Zyy/NZaOIpL47h4rms2N6j5ltbfBcit+5bJo659VruP7c41mzaoxFwJpVY1x/7vEWPsPrHMzR0oyqLJBPBb4GkJnfAX5lLr80l40ikvqusvnsmN5jZiuA51L8znXT1DmvXsPmK1/HX1/wUjZf+TqL4+FmjpZ6qHIN8krgiY7b+yJiSWbubR9oNBoH/VKvZNBtfL9MTk7W+vzTlRRPSbFAefEMiVnnMxw8p+cynx3Te8wLj1rCvz6196AxLzxqCY1Gg/OP/zlu+vYke/ZN/ey+ZUcs4vzjf+5njxHL4d0nP59b/+6nPP7UXl541BIueM3PE8t30mjsPOixS5tDpcUzJCqb03Up6X1SUixQVjwlxdJLlQXyTmBFx+3F0yfe+Pj4Qb+0etX2GTeKdBvfL41Go9bnn66keEqKBcqKZ2Jiou4QFsqs8xkOntNzmc+O6T3m6rNXdl0bfPXZr2B8fA3j47Bm9exrncfH4dI3H/RUXZU0h6CseJzTZeZoKOt9UlIsUFY8JcUCM8/pKpdYbAbOAoiIk4Gtc/kl+ydKRapsPjum95i5rA1uL4345xve7NIIzZU5WuqhyjPIdwFvjIhvA4uA35nLL9k/USpSZfPZMbN/3tkySxUwR0s9VFYgZ+ZzwMXz+d12MijtNLw0qqqez3MpABd6zCDFIy00c7TU20BealqSJEmqigWyJEmS1MECWZIkSeqwaGpqavZRFZiYmKjniaU+O/HEExfVHUM/OKc1KpzT0nDpNqdrK5AlSZKkErnEQpIkSepggSxJkiR1sECWJEmSOlR5Jb15iYjFwM3AK4E9wDsz89Ea41kKfAY4DlgGXJeZX6krnlZMxwATwBsz85GaY7kKeAtwJHBzZn66xliWArfS/P9qH3Bh3X8fOafnGJNz+uA4nM+FKmlOlzifoZw5Xcp8bsUyUHO6xDPI5wDLM/PXgCuBP6k3HN4O/DgzTwPOBD5eZzCtN9gngd11xtGKZR1wCrAWOAN4ca0BwVnAksw8Bfgj4AM1x6Omc3BOz8g5PSPnc7nOoZw5XdR8hnLmdGHzGQZsTpdYIJ8KfA0gM78D/Eq94fAl4NqO23vrCqTlI8AngB/WHAfAemArcBfwVeCeesPhe8CS1tmNlcCzNcejJud0b87p7pzP5SppTpc2n6GcOV3SfIYBm9MlFsgrgSc6bu+LiNqWgmTmk5m5KyJWAHcAG+qKJSJ+G3g8M++rK4ZpXkDzg/E84GLg8xFRZ3/QJ2l+dfMIsBG4qcZYtJ9zegbO6Z6cz+UqZk6XNJ+huDld0nyGAZvTJRbIO4EVHbcXZ2at/yKMiBcD3wQ+l5lfqDGUdwBvjIhvAa8CbouIY2uM58fAfZn5TGYmMAm8sMZ43tuK55doro27NSKW1xiPmpzTM3NOz8z5XK6i5nRB8xnKmtMlzWcYsDld3CY9YDPwG8BfRMTJNL8eqE1E/ALwdeDdmfmNOmPJzNPbP7cm38WZ+aP6IuJB4PKIuBF4EXAUzQlZl5+y/yubnwBLgSPqC0ctzukZOKd7cj6Xq5g5XdJ8huLmdEnzGQZsTpdYIN9F819f3wYWAb9TczxXAz8PXBsR7XVOZ2Zm7Rtq6paZ90TE6cBDNL+NuDQz99UY0keBz0TEJpo7dq/OzKdqjEdNzukBUdicdj6Xq6Q57XyeQWHzGQZsTnupaUmSJKlDiWuQJUmSpNpYIEuSJEkdLJAlSZKkDhbIkiRJUgcLZEmSJKmDBbIkSZLUwQJZkiRJ6vD/AeG00ge4phtMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(10,3))\n",
    "\n",
    "ax1.scatter(x, x)\n",
    "ax1.set_ylabel(\"$x$\")\n",
    "ax2.scatter(x, e_x)\n",
    "ax2.set_ylabel(\"$e^x$\")\n",
    "ax3.scatter(x, ln_e_x)\n",
    "ax3.set_ylabel(\"$log(e^x)$\")\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason you would apply a log transformation is that you are trying to go from the middle graph (exponential relationship) to the graph on the right (linear relationship).\n",
    "\n",
    "However if you apply a log transformation when the original relationship wasn't exponential, then you will get something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# natural log of x (adding 1 because log(0) is undefined)\n",
    "ln_x = np.log(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(7, 3))\n",
    "\n",
    "ax1.scatter(x + 1, x + 1)\n",
    "ax1.set_ylabel(\"$x$\")\n",
    "ax2.scatter(x + 1, ln_x)\n",
    "ax2.set_ylabel(\"$log(x)$\")\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see something like the plot on the right after you perform the log transformation, then a log transformation was probably not the appropriate approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Auto MPG Model\n",
    "\n",
    "Let's look at a baseline model that uses the Auto MPG dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3504</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3693</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3436</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3433</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3449</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2790</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2130</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2295</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2625</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2720</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight  model year\n",
       "0      3504          70\n",
       "1      3693          70\n",
       "2      3436          70\n",
       "3      3433          70\n",
       "4      3449          70\n",
       "..      ...         ...\n",
       "387    2790          82\n",
       "388    2130          82\n",
       "389    2295          82\n",
       "390    2625          82\n",
       "391    2720          82\n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"auto-mpg.csv\")\n",
    "y_raw = data[\"mpg\"]\n",
    "X_raw = data[[\"weight\", \"model year\"]]\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.808\n",
      "Model:                            OLS   Adj. R-squared:                  0.807\n",
      "Method:                 Least Squares   F-statistic:                     819.5\n",
      "Date:                Mon, 09 Oct 2023   Prob (F-statistic):          3.33e-140\n",
      "Time:                        14:23:42   Log-Likelihood:                -1037.6\n",
      "No. Observations:                 392   AIC:                             2081.\n",
      "Df Residuals:                     389   BIC:                             2093.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -14.3473      4.007     -3.581      0.000     -22.224      -6.470\n",
      "weight        -0.0066      0.000    -30.911      0.000      -0.007      -0.006\n",
      "model year     0.7573      0.049     15.308      0.000       0.660       0.855\n",
      "==============================================================================\n",
      "Omnibus:                       42.504   Durbin-Watson:                   1.230\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               71.997\n",
      "Skew:                           0.670   Prob(JB):                     2.32e-16\n",
      "Kurtosis:                       4.616   Cond. No.                     7.17e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.17e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "baseline_model = sm.OLS(y_raw, sm.add_constant(X_raw))\n",
    "baseline_results = baseline_model.fit()\n",
    "print(baseline_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Evaluation and Interpretation\n",
    "\n",
    "The baseline model is statistically significant overall, and explains about 81% of the variance in MPG.\n",
    "\n",
    "The coefficients for the intercept, `weight`, and `model year` are statistically significant.\n",
    "\n",
    "* For a car with 0 cylinders, weighing 0 lbs, and built in 1900, we would expect an MPG of about -14\n",
    "* For each increase of 1 lb in weight, we see an associated decrease of about 0.007 MPG\n",
    "* For each increase of 1 year in model year, we see an associated increase of about 0.76 in MPG\n",
    "\n",
    "Let's say we have some reason to believe that the relationship between weight and MPG is not linear. Can we address it using a log transformation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transforming a Feature\n",
    "\n",
    "Let's try building a model that uses the log of `weight` rather than the raw values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>log(weight)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3504</td>\n",
       "      <td>8.161660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3693</td>\n",
       "      <td>8.214194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3436</td>\n",
       "      <td>8.142063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3433</td>\n",
       "      <td>8.141190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3449</td>\n",
       "      <td>8.145840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2790</td>\n",
       "      <td>7.933797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2130</td>\n",
       "      <td>7.663877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2295</td>\n",
       "      <td>7.738488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2625</td>\n",
       "      <td>7.872836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2720</td>\n",
       "      <td>7.908387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight  log(weight)\n",
       "0      3504     8.161660\n",
       "1      3693     8.214194\n",
       "2      3436     8.142063\n",
       "3      3433     8.141190\n",
       "4      3449     8.145840\n",
       "..      ...          ...\n",
       "387    2790     7.933797\n",
       "388    2130     7.663877\n",
       "389    2295     7.738488\n",
       "390    2625     7.872836\n",
       "391    2720     7.908387\n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weight_log = X_raw.copy()\n",
    "\n",
    "X_weight_log[\"log(weight)\"] = np.log(X_weight_log[\"weight\"])\n",
    "\n",
    "# Visually inspect raw vs. transformed values\n",
    "X_weight_log[[\"weight\", \"log(weight)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAADKCAYAAAAIGS/SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT6klEQVR4nO3de7BddXXA8e9FEhEIqKWITJHQgsuro1LjiPJIUhoeAQTtqG0ZFaSCtun4YpSHUasjNbaIj1qKRjGgUqeAMAqNpEWC4Au5xkrKYVGE9GVVQLGhGCDk9o+9rxzg3tyT8/qdk/P9zNyZc/Y+e5919937rv377f1be2xychJJkkraoXQAkiSZjCRJxZmMJEnFmYwkScWZjCRJxe3YqxVPTEx4m56G3oIFC8ZKxzDFY0rbi+mOq54lo/oLe7l6ABqNBuPj4z3/nm4axphh9OKemJjoQTSd6eUxNax/315zuzxRJ9tkpuPKbjpJUnEmI0lScSYjSVJxJiNJUnEmI0lScSYjSVJxPb21u5fmn3l107s7t3n5DSuO7V4wkuCSDodknegwqlFmy0iSVJzJSJJUnMlIklScyUiSVJzJSJJUnMlIklScyUiSVJzJSJJU3NAOepWGWUScBRwPzAXOB64HVgGTwHpgWWZuKRag1Ge2jKQ+i4jFwMHAIcAiYB/gPGB5Zh4GjAEnFAtQKsBkJPXfUcAtwBXAV4GrgAVUrSOA1cCSMqFJZdhNJ/XfHsC+wHHAfsBXgB0yc6o420Zg9+kWbDQaPQtq06ZNHa2/0wdz9/J360Sn22V71IttMmsyiog5wEXAfOAR4FRgM/ZvS+26F7gtMx8CMiI2UXXVTZkH3DfdguPjnf7Ln1mj0ehs/es6+/5e/m6d6Hi7bIc62SYTExPTTm+lm+4YYMfMPBj4AHAO9m9LnbgRODoixiJib2AX4Nr6WhLAUuCGUsFJJbSSjG4HdoyIHYDdgIexf1tqW2ZeRdWOuInqmtEy4HTg/RHxbao77C4rF6HUf61cM7qfqovuNqq+7uOAhaX7tztVMrZh7YM27u7JzHdNM3lR3wORBkQryejtwDWZeVZE7AN8nerMbUqR/u12HqjXrGQf8LD2QY9a3DP1bUvqvla66X4B/LJ+/XNgDrDO/m1JUre00jL6KHBhRNxA1SI6G7gZWBkRc4EG9m9LkjowazLKzPuB10wzy/5tSVJXWIFBklScyUiSVJzJSJJUnMlIklScyUiSVJzJSJJUnMlIklScyUiSVJzJSJJUnMlIklScjx2XtP24ZKyz5U+cnP0z6glbRpKk4mwZSQVExDoefTTLXcA5wCpgElgPLMvMLWWik/rPZCT1WUTsBJCZi5umfQVYnplrI+IC4ATgijIRSv1nMpL674XAzhGxhuoYPBtYAFxfz18NHInJSCPEZCT13wPAucBngAOoks9YZk5dPd8I7D7dgo1Go2dBbdq0qaP1d/pA+m78br2IodPtsj3qxTYxGUn9dztwR518bo+Ie6laRlPmAfdNt+D4eKf/bmfWaDQ6W/+6zr6/K79bD2LoeLtshzrZJhMTE9NO9246qf9OAT4CEBF7A7sBayJicT1/KXBDmdCkMmwZSf33WWBVRNxIdffcKcA9wMqImAs0gMsKxif1nclI6rPMfAg4cZpZi/odizQo7KaTJBVnMpIkFWcykiQVZzKSJBXnDQySNGWaqt/j0Pr4Jat+t82WkSSpOJORJKm4lrrpIuIs4HhgLnA+VUHHVVjuXpIe5cP92jZry6guUXIwcAjVoLx9gPOoyt0fBoxRlbuXJKktrbSMjgJuoSpnvxvwTuBULHcvSYNliFtmrSSjPYB9geOA/YCvADuULnffqZKxDWtJeuOW1CutJKN7gdvqeloZEZuouuqmFCl3D3d2tHTJkvDDWpJ+1OKeqdS9pO5r5W66G4GjI2KsLne/C3Ct5e4lSd0ya8soM6+KiIXATVTJaxlwF0Ne7n7+mVd3tPyGFcd2KRJJUku3dmfmu6aZbLl7SVJXOOhVklSctemkAiJiT2ACOALYjIPIO78tWUPNlpHUZxExB/gU8Kt6koPINfJMRlL/nQtcAPy4fr+Axw4iX1IiKKkku+mkPoqIk4G7M/OauuYjwFgrg8iht4O1Ox0cPHwj0AZPp3/fTv8GrX5/LwaSm4yk/joFmIyIJcCBwMXAnk3zZxxEDr0drN3xoOZWn/mjGXX89+3wb9Dq93eyr8w0mNxuOqmPMnNhZi7KzMXAD4DXA6sdRK5RZ8tIKu90hnwQudQpk5FUSN06muIgco00k1GbOi0nBHdaUkgDZXzdc73uo2K8ZiRJKs5kJEkqzmQkSSrOa0aSNChGuD6fLSNJUnEmI0lScSYjSVJxJiNJUnEmI0lScSYjSVJxJiNJUnEmI0lScSYjSVJxJiNJUnEmI0lScdamk/osIp4ErAQCeAR4AzAGrAImgfXAsszcUipGqd9sGUn993KAzDwEeC9wXv2zPDMPo0pMJ5QLT+q/llpGEbEnMAEcAWzGMzipbZl5ZURcVb/dF/gpcCxwfT1tNXAkcEWB8KQiZk1GETEH+BTwq3rS1Bnc2oi4gOoMzoNG2gaZuTkiLgJeCbwKOC4zJ+vZG4Hdp1uu0Wj0LKbxnq1Zw6LV/WvTpk1d3xdbaRmdC1wAnFW/X0CLZ3C9PHC2B51un6UX3dnR8qtP+u1t+nwvdsB+GNS4M/OkiDgD+C7wlKZZ84D7pltmfLyHKWNd71at4dDq/tVoNNreFycmJqadvtVkFBEnA3dn5jURMZWMxlo5g4MeHzh09o94EHS+fTrbBtv6/Z3sgCW1G/dMB02nIuJ1wG9l5oeAB4AtwM0RsTgz1wJLget68uXSgJqtZXQKMBkRS4ADgYuBPZvmz3gGJ2lGXwY+FxHfAOYAbwMawMqImFu/vqxceFL/bTUZZebCqdcRsRZ4M/DXnsFJ7cvM/wNeM82sRf2ORRoU7YwzOh3P4CRJXdRyMsrMxU1vPYOTJHWNg14lScVZDqig+WdeXToESRoItowkScWZjCRJxZmMJEnFec1Ibev0mteGFcd2KRJJw86WkSSpOJORJKk4k5EkqTiTkSSpOJORJKk4k5Ekqbhit3ZbCkeSNMWWkSSpOAe9jrD2WqfD/7j30iJiDnAhMB94MvBB4FZgFTAJrAeWZeaWQiFKfWfLSOq/1wL3ZuZhVE9L/iRwHrC8njYGnFAwPqnvTEZS/10KvKfp/WZgAXB9/X41sKTfQUkl2U0n9Vlm3g8QEfOAy4DlwLmZOVl/ZCOw+3TLNhqNnsU13rM1a1i0un9t2rSp6/uiyUgqICL2Aa4Azs/MSyLir5pmzwPum2658fEepox1vVu1hkOr+1ej0Wh7X5yYmJh2ut10Up9FxDOANcAZmXlhPXldRCyuXy8FbigRm1SKLSOp/84Gnga8JyKmrh29FfhERMwFGlTdd9LIMBlJfZaZb6VKPo+3qN+xSIPCbjpJUnEmI0lScSYjSVJxJiNJUnHewCBJqlwy1tLHxmH6cWknTk4zsTVbTUYWdJQk9cNs3XQWdJQk9dxs3XSX8tjBd9MVdDySqqzJE/SyjpaGX7/2j17U0ZLUXVtNRp0UdITZ6hz5XJxR19M6a03araM1Uw0tSd036910dUHH64DPZ+YlQPP1oRkLOkqS1KqtJiMLOkqS+mG2a0YWdFTPtPfY80dtWHFslyKRVNps14ws6ChJ6jkrMEiSijMZSZKKMxlJkoqzNp1UQEQcBHw4MxdHxP5YYksjzpaR1GcR8S7gM8BO9SRLbGnk2TKS+u9HwB8An6/fD0SJrf7Uw9D2rJP902Qk9VlmXh4R85smjXWnxFaHpnskgLQNWtk/ZyqzZTedVJ4ltjTybBlJ5a2LiMWZuZaqxNZ1ba2lxQejSYPIZCSVdzqw0hJbGmUmI6mAzNwAvLR+fTuW2NKI85qRJKk4k5EkqTiTkSSpOJORJKk4k5EkqTiTkSSpOJORJKk4k5EkqTgHvWpozT/z6m349J1PmLJhxbHdC0ZSR2wZSZKKMxlJkoozGUmSijMZSZKKMxlJkoozGUmSijMZSZKKa2ucUUTsAJwPvBB4EHhjZt7RzcCkUeIxpVHXbsvoFcBOmfky4EzgI12LSBpNr8BjSiOs3QoMhwJfA8jM70TEi6f70MTExIwruPzVe7X51VJ3bG3/LKDjY4q4uSeBSS3r4JhqNxntBvyy6f0jEbFjZm6emrBgwYKxtqOSRo/HlEZau910/wvMa15P80EjaZt5TGmktZuMvgkcAxARLwVu6VpE0mjymNJIa7eb7grgiIj4FjAGvKF7IUkjyWNKI21scnKydAxPEBFzgAuB+cCTgQ8CtwKrgElgPbAsM7dExKnAm4DNwAcz86qIeArwBWBPYCNwUmbe3Ye4nwSsBAJ4hOofytigx13HvicwARxRxzQMMa/j0essdwHnDEPcJUXEycDJ9dudgAOBvTLzvnr+O4A/Aaa2xZsyM/saZAH1/5yLqP7nPAKcmpm3Nc1/OfBeqn3owsxcWSLOfmthu3RtfxnUQa+vBe7NzMOApcAngfOA5fW0MeCEiNgLeAtwCHAU8KGIeDLwp8At9WcvBpb3Ke6XA2TmIVQ77nnDEHe9w30K+FU9aRhi3gkgMxfXP28YhrhLy8xVU9uM6uTjLVOJqPYi4PVN23W7T0S1Y4AdM/Ng4ANUJzbAr4+PjwJHAouA0+r9ahTMuF1qXdtfBjUZXQq8p+n9ZmABcH39fjWwBHgJ8M3MfDAzfwncAbyApttkmz7bc5l5JXBa/XZf4KfDEDdwLnAB8OP6/TDE/EJg54hYExFfr6+zDEPcA6G+dfx5mfnpx81aAJwVETdGxFkFQivldmDHevDxbsDDTfPGgTsy8xeZ+RBwI3BYgRhL2Np2gS7uLwOZjDLz/szcGBHzgMuozlrHMnOqT3EjsDtPvB12uulT0/oiMzdHxEXA31DFPtBx1902d2fmNU2TBzrm2gNUSfQo4M3AFxmOuAfF2cD7p5n+JarteThwaEQc19eoyrmfqivqNqqu9k80zZtpHxoFW9su0MX9ZSCTEUBE7ANcB3w+My8BtjTNngfcxxNvh51u+tS0vsnMk4BnU/3xntI0axDjPoXqwvlaqusHF1NdR9labDNN7+e2vh34QmZOZubtwL3AM2aJb6bpfd9HSoqIpwLPyczrHjd9DPhYZt5TtwCuBn63QIglvB24JjOfTdXqvmiqK5iZ96FRMON26fb+MpDJKCKeAawBzsjMC+vJ6yJicf16KXADcBNwWETsFBG7UzWn19N0m2zTZ/sR9+uamqoPUCXQmwc57sxcmJmL6msIPwBeD6we5Jhrp1CXzImIvanOXtcMQdyDYCHwz9NM3w1YHxG71v9oDqe6rjQKfsGjrZ+fA3OAJ9XvG8ABEfH0iJhLtf2+3f8Qi9jadunq/jKod9N9HPhDqqbhlLdSNRHnUu0cp2bmI/WdUqdRJda/zMzLI2JnqjtAngk8BJyYmT/pQ9y7AJ8D9qL6o62oY105yHE3xb+Wqsm9ZdBjrv8prAKeRXX33BnAPYMe9yCIiHcCD2fmx+r3JwK7ZuanI+J1VDd8PAhcm5nvKxdp/0TErlR38D6Tav/5eD1rartM3U23A9XddH9bJtL+amG7dG1/GchkJEkaLQPZTSdJGi0mI0lScSYjSVJxJiNJUnEmI0lScSajIRMRZ0bES7Yyf21EPGea6X/e28ik3ouIkyNiRRvLnR0RC9r8zo9FxLO2Mn9D0wDZqWk7RcQb69fPj4iRuEW+EyajIZOZKzLzpjYWHYlCoNLj1dVcnp+ZbQ3IzMy3ZeZ/bONiewFvrJe/Bdg/In6nne8fFe0+z0hdEhHfB46mGul8L7AoM9fV0y8C/ohqUOeXMvMTEbGKqh7U9VSle/YG/hNYmJl716t9X13FYhfgj+ufp0fE+Zn5Z/377aTeiIjTqY6NzcA3MvOMiNgDuITqsTMJHJ6Z+1NVaL+sfsTLbVRVOH4T+C+q0lf3A9/OzBdFxIeoKizsAJyXmZc2DQa/Z4b1A/xdROxXv34l8G7guRHx3sz8APAPwDLgHT3bKEPOllF5V1IV+zyU6pk8R0TEc6mqS7+6nn4o8IqIiKblTgPuqh9X8Rc8ti7b1Zl5OFU16ldl5jnAz01E2k4cALwGOLj+OaAu0Plu4MrMXERV+X/qZHsx8MPMfISq7NPLqE4A1wO/X/+siYilwH71MfV7wLvrOn5TZlo/wGfrklobqJ4Jdg5wa52IAH5Yx6EZmIzK+zJVjbSjqXb2JcDxwOVUj6G4Fvg68BvA/k3LjQPfAqgfdtX8YLip7oifADv3MHaphAOB72Tmw3WV9huA59F0TPDYWoN7UD3OBR493o6iOt6O4NHj7fnAgrol9DWqkl77Nq1npvXD7Mfc/1Adw5qByaiwzFwP7Ef13J1/BHYFTqDqTvhX4PfqM65VwC1Ni66nOsOj7oveo2nedDWexroculTKD4CDImLHukDnQqoq7r8+JoCXNn3+Z8BT69f/RPWAvD2ojrcFwIGZ+T2qY+66+ng7nKpr7c6m9cy0fnjiMbeFx/5/fVodh2ZgMhoM11M9U2hL/fpnmfkvVK2iGyPiZqquif9uWuazwPyI+AZVN92mWb7j1oj4Qtcjl/rv36gSxTepqrJvoOruXgEcHxHXAafy6IPg1gIHAWTmg1TXWL9fH28JfLf+3FeB+yPiBqqWzmRmbmz63pnWP52fAXMj4sP1+4OojmfNwEKpQyoiDqaqnLsmIg4AvpaZ3q2jkRURx1Cd1H0vIpYAZ2fm4RGxL3BuZr66F+tvcdkvAssz865OYtieeTfd8LoT+Pt6/MIcqjt1pFF2F3BhRGymeubOWwAy898j4ocR8eLMvLnb659NRLwA+JGJaOtsGUmSivOakSSpOJORJKk4k5EkqTiTkSSpOJORJKm4/wevVaJZliN41QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distributions of raw vs. transformed values\n",
    "# (scales are so different that it's not reasonable to share an x-axis)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(7,3))\n",
    "ax1.hist(X_weight_log[\"weight\"])\n",
    "ax1.set_xlabel(\"weight\")\n",
    "ax2.hist(X_weight_log[\"log(weight)\"], color=\"orange\")\n",
    "ax2.set_xlabel(\"log(weight)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the distribution of the predictor is changed by applying the log transformation. Unlike a linear transformation that just \"moves\" or \"stretches\" the transformed variable, this transformed variable has a different skew as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log(weight)</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.161660</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.214194</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.142063</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.141190</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.145840</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>7.933797</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>7.663877</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>7.738488</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>7.872836</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>7.908387</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log(weight)  model year\n",
       "0       8.161660          70\n",
       "1       8.214194          70\n",
       "2       8.142063          70\n",
       "3       8.141190          70\n",
       "4       8.145840          70\n",
       "..           ...         ...\n",
       "387     7.933797          82\n",
       "388     7.663877          82\n",
       "389     7.738488          82\n",
       "390     7.872836          82\n",
       "391     7.908387          82\n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping original weight column\n",
    "X_weight_log.drop(\"weight\", axis=1, inplace=True)\n",
    "\n",
    "# Reordering columns for easier comparison\n",
    "X_weight_log = X_weight_log[[\"log(weight)\", \"model year\"]]\n",
    "\n",
    "X_weight_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with a Log Transformed Feature\n",
    "\n",
    "Now let's build a model where `cylinders` and `model year` are still in their original units, while `weight` has been log transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline model adjusted R-Squared:    0.8071940863723529\n",
      "log(weight) model adjusted R-Squared: 0.8364670750279435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_log_model = sm.OLS(y_raw, sm.add_constant(X_weight_log))\n",
    "weight_log_results = weight_log_model.fit()\n",
    "\n",
    "print(f\"\"\"\n",
    "Baseline model adjusted R-Squared:    {baseline_results.rsquared_adj}\n",
    "log(weight) model adjusted R-Squared: {weight_log_results.rsquared_adj}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.837\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     1001.\n",
      "Date:                Mon, 09 Oct 2023   Prob (F-statistic):          4.10e-154\n",
      "Time:                        14:25:21   Log-Likelihood:                -1005.3\n",
      "No. Observations:                 392   AIC:                             2017.\n",
      "Df Residuals:                     389   BIC:                             2028.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         127.2362      6.587     19.316      0.000     114.285     140.187\n",
      "log(weight)   -20.4949      0.593    -34.585      0.000     -21.660     -19.330\n",
      "model year      0.7809      0.045     17.263      0.000       0.692       0.870\n",
      "==============================================================================\n",
      "Omnibus:                       57.816   Durbin-Watson:                   1.301\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              127.132\n",
      "Skew:                           0.773   Prob(JB):                     2.48e-28\n",
      "Kurtosis:                       5.323   Cond. No.                     3.17e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.17e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(weight_log_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const        -14.347253\n",
       "weight        -0.006632\n",
       "model year     0.757318\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          127.236211\n",
       "log(weight)    -20.494864\n",
       "model year       0.780894\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_log_results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike when performing linear transformations on a feature, we have now built **an entirely different model** due to the log transformation. Only the `model year` coefficient looks approximately the same as in the baseline model, whereas everything else is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Coefficients for a Transformed Feature\n",
    "\n",
    "Overall it seems like this is a better model than the baseline model, since it has a higher adjusted R-Squared and aligns with our domain knowledge indicating that the relationship is not linear.\n",
    "\n",
    "So, if we wanted to use this new model instead of the baseline one, how can we interpret its coefficients?\n",
    "\n",
    "For the coefficients that were not transformed, their interpretation is the same. For example, the interpretation of `model year`'s coefficient is now:\n",
    "\n",
    "> For each increase of 1 year in model year, we see an associated increase of about 0.78 in MPG\n",
    "\n",
    "The log transformed coefficient is more complicated. It would be technically correct, but not particularly useful, to say this:\n",
    "\n",
    "> For each increase of 1 in the natural log of the weight, we see an associated decrease of about 20 in MPG\n",
    "\n",
    "But what does it mean to increase the natural log of the weight by 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformed Coefficients are Multiplicative\n",
    "\n",
    "If we add 1 to the natural log of the weight, that means we are _multiplying_ the underlying variable by $e$. So another technically correct explanation would be:\n",
    "\n",
    "> For each time we multiply the weight by about 2.72 ($e$), we see an associated decrease of about 20 in MPG\n",
    "\n",
    "That might be a bit easier to picture (a car that is almost 3x as large would get much worse gas mileage) but it's still tough to make sense of the underlying insight. So, what if we increase the natural log of the weight by something other than 1 unit?\n",
    "\n",
    "We usually use a 1-unit increase in the predictor for a linear relationship, but that is only because it happens to be the easiest way to interpret a linear coefficient. For a non-linear coefficient, we can choose another number.\n",
    "\n",
    "The number that we choose most often for log transformed coefficients is **1%** rather than 1 unit. If we use 1% as the increase in `weight`, then we also need to transform the associated coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.494864367076012"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_log_results.params[\"log(weight)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2039306812432118"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_log_results.params[\"log(weight)\"] * np.log(1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a quicker way to do this, which takes advantage of a property of the natural logarithm where:\n",
    "\n",
    "$$ log(1.01) \\approx 0.01 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009950330853168092"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can just look at the original coefficient and multiply it by 0.01, i.e. divide it by 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20494864367076013"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_log_results.params[\"log(weight)\"]  / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small difference in the result, but it's usually the part of the result that would be rounded off when reporting findings to stakeholders.\n",
    "\n",
    "So, **the conventional way to interpret a log-transformed coefficient is like this**:\n",
    "\n",
    "> For each increase of 1% in `<feature>`, we see an associated change of `<coefficient / 100>` in `<target>`\n",
    "\n",
    "For this particular model, that means:\n",
    "\n",
    "> For each increase of 1% in weight, we see an associated decrease of about 0.2 in MPG\n",
    "\n",
    "This 1% interpretation is popular because it's fairly easy to divide a value by 100 in your head rather than actually calculating the log value.\n",
    "\n",
    "As noted previously, this is based on an approximation, $log(1.01) \\approx 0.01$. If we wanted to use a percentage larger than 1%, we shouldn't simply scale the parameter by that percentage, since the approximation gets worse for larger values.\n",
    "\n",
    "Let's take 50% as an example. $log(1.5)$ would represent a 50% increase in a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4054651081081644"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this number is proportionally farther away from 0.5 than $log(1.01)$ was from 0.01.\n",
    "\n",
    "To describe this in terms of a 50% increase, we would want to multiply the coefficient by this value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.309952396258641"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_log_results.params[\"log(weight)\"] * np.log(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to interpret this in words would be:\n",
    "\n",
    "> For each increase of 50% in weight, we see an associated decrease of about 8.3 MPG\n",
    "\n",
    "Note that this is pretty different from if we had just divided the coefficient (20.5) in half. This interpretation (an increase of a larger percentage) is less popular than increasing by 1% because multiplying a value by something like 0.405 is harder to do mentally than dividing by 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with a Log Transformed Target\n",
    "\n",
    "Transforming the target ($y$) of a linear regression impacts not only the interpretation of the coefficients, but also the interpretation of the model overall.\n",
    "\n",
    "If you fit a model with a log-transformed target, the algorithm will be minimizing the errors in $log(y)$ units rather than $y$ units. In other words, minimizing the percentage/proportional/multiplicative error rather than the raw additive error.\n",
    "\n",
    "This also means that **the R-Squared (percentage of variance explained) and RMSE (average error) cannot be compared between models with raw $y$ and $log(y)$ targets**. Instead you will need to rely on other factors, including domain understanding, to determine whether transforming the target improves the model.\n",
    "\n",
    "Let's build a model where the target (MPG) is log-transformed, with the original (raw) predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.890372\n",
       "1      2.708050\n",
       "2      2.890372\n",
       "3      2.772589\n",
       "4      2.833213\n",
       "         ...   \n",
       "387    3.295837\n",
       "388    3.784190\n",
       "389    3.465736\n",
       "390    3.332205\n",
       "391    3.433987\n",
       "Name: log(mpg), Length: 392, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log = np.log(y_raw)\n",
    "y_log.name = \"log(mpg)\"\n",
    "y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distributions of raw vs. transformed values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "ax.hist(y_raw, label=\"MPG\")\n",
    "ax.hist(y_log, color=\"orange\", label=\"log(MPG)\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               log(mpg)   R-squared:                       0.871\n",
      "Model:                            OLS   Adj. R-squared:                  0.870\n",
      "Method:                 Least Squares   F-statistic:                     1310.\n",
      "Date:                Mon, 09 Oct 2023   Prob (F-statistic):          1.59e-173\n",
      "Time:                        14:30:36   Log-Likelihood:                 268.08\n",
      "No. Observations:                 392   AIC:                            -530.2\n",
      "Df Residuals:                     389   BIC:                            -518.2\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6397      0.143     11.442      0.000       1.358       1.921\n",
      "weight        -0.0003   7.67e-06    -40.212      0.000      -0.000      -0.000\n",
      "model year     0.0313      0.002     17.683      0.000       0.028       0.035\n",
      "==============================================================================\n",
      "Omnibus:                        7.706   Durbin-Watson:                   1.334\n",
      "Prob(Omnibus):                  0.021   Jarque-Bera (JB):               11.581\n",
      "Skew:                          -0.096   Prob(JB):                      0.00306\n",
      "Kurtosis:                       3.820   Cond. No.                     7.17e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.17e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y_log_model = sm.OLS(y_log, sm.add_constant(X_raw))\n",
    "y_log_results = y_log_model.fit()\n",
    "\n",
    "print(y_log_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Coefficients for a Transformed Target\n",
    "\n",
    "This model is statistically significant overall, and explains about 87% of the variance of the log-transformed MPG. This is not directly comparable to the R-Squared values for the previous models, but at a high level it tells us that the model fits are about the same whether or not the target has been transformed.\n",
    "\n",
    "Once again, we could interpret the coefficients in a way that is technically correct but not especially useful:\n",
    "\n",
    "> For each increase of 1 lb in weight, we see an associated decrease of about 0.0003 in the natural log of the MPG\n",
    "\n",
    "> For each increase of 1 year in model year, we see an associated increase of about 0.03 in the natural log of the MPG\n",
    "\n",
    "Again, changes to the natural log of a variable are not easy to grasp. Instead, we can frame the change in the MPG in terms of a multiplier. We'll focus on the `weight` coefficient specifically here but it's the same for all predictor coefficients.\n",
    "\n",
    "A decrease in $log(MPG)$ of 0.0003 is equivalent to multiplying MPG by $e^{0.0003}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00030860096419965975"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log_results.params[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99969144664818"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(y_log_results.params[\"weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, increasing `weight` by 1 causes MPG to become about 99.969% of its original value. Another way to frame this is in terms of reducing by a percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.030855335182000676"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- (1 - np.exp(y_log_results.params[\"weight\"])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is basically the same as if we had just multiplied the original coefficient by 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.030860096419965975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log_results.params[\"weight\"] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to another approximation, that for small values of $\\beta$,\n",
    "\n",
    "$$ e^\\beta \\approx 1 + \\beta $$\n",
    "\n",
    "Thus **for small coefficients, the conventional way to interpret a log-transformed target is this:**\n",
    "\n",
    "> For each increase of 1 unit in `<feature>`, we see an associated change of `<coefficient * 100>`% in `<target>`\n",
    "\n",
    "For this particular model, that means:\n",
    "\n",
    "> For each increase of 1 lb in weight, we see an associated decrease of about 0.03% in MPG\n",
    "\n",
    "> For each increase of 1 year in model year, we see an associated increase of about 3.1% in MPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we had a model with much larger coefficients? For example, if the weight were in **tons** rather than **pounds**?\n",
    "\n",
    "We'll use the US ton, where 1 ton = 2000 lbs, and will apply a linear transformation to change the units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.7520</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.8465</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.7180</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.7165</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.7245</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1.3950</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1.0650</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.1475</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1.3125</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight  model year\n",
       "0    1.7520          70\n",
       "1    1.8465          70\n",
       "2    1.7180          70\n",
       "3    1.7165          70\n",
       "4    1.7245          70\n",
       "..      ...         ...\n",
       "387  1.3950          82\n",
       "388  1.0650          82\n",
       "389  1.1475          82\n",
       "390  1.3125          82\n",
       "391  1.3600          82\n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weight_tons = X_raw.copy()\n",
    "\n",
    "X_weight_tons[\"weight\"] = X_weight_tons[\"weight\"] / 2000\n",
    "X_weight_tons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const         1.639728\n",
       "weight       -0.617202\n",
       "model year    0.031291\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tons_model = sm.OLS(y_log, sm.add_constant(X_weight_tons))\n",
    "weight_tons_results = weight_tons_model.fit()\n",
    "\n",
    "weight_tons_results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a **larger coefficient**, there is more of a difference between actually calculating the change vs. using the approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46.05482475477222"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(weight_tons_results.params[\"weight\"]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-61.72019283993188"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tons_results.params[\"weight\"] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore instead of just multiplying the coefficient by 100, we'll use the value produced by the actual math:\n",
    "\n",
    "> For each increase of 1 ton in weight, we see an associated decrease of about 46% in MPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach runs into problems if you have **even larger coefficients** due to the nature of exponential growth. For example, if you had a coefficient of 1000, taking the exponent will actually exceed the amount of space allotted for a 64-bit floating point number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-47a6eab891c2>:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The term \"overflow\" means we have exceeded the limit, so the value gets represented as `inf`, i.e. infinity, even though it isn't actually infinitely large.)\n",
    "\n",
    "Fortunately you can usually use scaling to change the units of the coefficient and avoid this challenge while still producing an interpretable result. If the coefficient is too large, you can either scale the target units to be larger (e.g. a price in thousands of dollars rather than dollars) or scale the predictor units to be smaller (e.g. a weight in pounds rather than tons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with a Log Transformed Predictor and Target\n",
    "\n",
    "You are not limited to log-transforming just the predictor or the target. You can also transform both!\n",
    "\n",
    "Here we'll use existing variables `y_log` (log-transformed MPG) and `X_weight_log` (log-transformed weight, raw model year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               log(mpg)   R-squared:                       0.881\n",
      "Model:                            OLS   Adj. R-squared:                  0.880\n",
      "Method:                 Least Squares   F-statistic:                     1436.\n",
      "Date:                Mon, 09 Oct 2023   Prob (F-statistic):          2.38e-180\n",
      "Time:                        14:34:18   Log-Likelihood:                 283.91\n",
      "No. Observations:                 392   AIC:                            -561.8\n",
      "Df Residuals:                     389   BIC:                            -549.9\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           8.0395      0.246     32.720      0.000       7.556       8.523\n",
      "log(weight)    -0.9341      0.022    -42.259      0.000      -0.978      -0.891\n",
      "model year      0.0328      0.002     19.450      0.000       0.029       0.036\n",
      "==============================================================================\n",
      "Omnibus:                        9.424   Durbin-Watson:                   1.396\n",
      "Prob(Omnibus):                  0.009   Jarque-Bera (JB):               16.664\n",
      "Skew:                           0.022   Prob(JB):                     0.000241\n",
      "Kurtosis:                       4.009   Cond. No.                     3.17e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.17e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "log_model = sm.OLS(y_log, sm.add_constant(X_weight_log))\n",
    "log_results = log_model.fit()\n",
    "\n",
    "print(log_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll focus on interpreting the coefficient for `weight` here, since the coefficient for `model year` has the same interpretation as in the model where just MPG was log-transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9340850470520534"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results.params[\"log(weight)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last time, we could interpret the coefficient like this and would be technically correct:\n",
    "\n",
    "> For each increase of 1 in the natural log of weight, there is a decrease of about 0.9 ($\\beta$) in the natural log of MPG\n",
    "\n",
    "Which also means:\n",
    "\n",
    "> For each time we multiply the weight by about 2.72 ($e$), we multiply MPG by about 0.4 ($e^{\\beta}$)\n",
    "\n",
    "But those numbers are still hard to grasp. So let's go back to setting the increase of the predictor to 1% rather than 1 unit.\n",
    "\n",
    "If `weight` increases by 1%, MPG is multiplied by $e^{log(1.01)\\beta}$, where $\\beta$ is the coefficient for weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907486046766623"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.log(1.01) * log_results.params[\"log(weight)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subtract 1 and multiply by 100 to interpret as a percentage change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9251395323337741"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(np.log(1.01) * log_results.params[\"log(weight)\"]) - 1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again because of the approximations discussed earlier, this is essentially the same as the original coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9340850470520536"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results.params[\"log(weight)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, regardless of which formula we use, we can conclude:\n",
    "\n",
    "> For each increase of 1% in weight, we see an associated decrease of about 0.9% in MPG\n",
    "\n",
    "Keep in mind that the approximation only works here because both the percentage and the coefficient are small enough. For larger values you would want to be sure to use the full formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway \"Cheat Sheet\"\n",
    "\n",
    "For faster reference, we've summarized all of the different coefficient interpretations below. We'll define $y$ as the dependent variable, $x$ as (one of) the independent variable(s), and $\\beta$ as the coefficient for $x$ found in a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Predictor vs. Raw Target\n",
    "\n",
    "This is just our regular linear regression. We are modeling the relationship as:\n",
    "\n",
    "$$ \\large{ y = \\beta x \\ldots } $$\n",
    "\n",
    "(The \"$\\ldots$\" is to indicate additional predictors, intercept, error, etc. that are not represented in this version of the formula.)\n",
    "\n",
    "To interpret $\\beta$ we would say:\n",
    "\n",
    "> For each increase of $\\large{1}$ unit in $\\large{x}$, we see an associated change of $\\large{\\beta}$ in $\\large{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformed Predictor vs. Raw Target\n",
    "\n",
    "We are modeling the relationship as:\n",
    "\n",
    "$$ \\large{ y = \\beta* log(x) \\ldots } $$\n",
    "\n",
    "(Note that this $\\beta$ will be a different value than the $\\beta$ in the previous equation, since it is modeling a different relationship.)\n",
    "\n",
    "To interpret $\\beta$ we would say:\n",
    "\n",
    "> For each increase of $\\large{1\\%}$ in $\\large{x}$, we see an associated change of $\\large{\\beta / 100}$ in $\\large{y}$\n",
    "\n",
    "That interpretation relies on the approximation $log(1.01) \\approx 0.01$. For a percentage larger than 1%, we can also use this formula:\n",
    "\n",
    "> For each increase of $\\large{p\\%}$ in $\\large{x}$, we see an associated change of $\\large{\\beta * log((100 + p)/100)}$ in $\\large{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Predictor vs. Log Transformed Target\n",
    "\n",
    "We are modeling the relationship as:\n",
    "\n",
    "$$ \\large{ log(y) = \\beta x \\ldots } $$\n",
    "\n",
    "For **small** values of $\\beta$, we can interpret $\\beta$ as:\n",
    "\n",
    "> For each increase of $\\large{1}$ unit in $\\large{x}$, we see an associated change of $\\large{(\\beta * 100)}\\%$ in $\\large{y}$\n",
    "\n",
    "That interpretation relies on the approximation $e^\\beta \\approx 1 + \\beta$ for small values of $\\beta$. For an interpretation that will work for **larger** values of $\\beta$, we can use this formula:\n",
    "\n",
    "> For each increase of $\\large{1}$ unit in $\\large{x}$, we see an associated change of $\\large{((e^\\beta - 1) * 100)}\\%$ in $\\large{y}$\n",
    "\n",
    "For **very large** values of $\\beta$ you likely need to scale the predictor and/or target to create a smaller coefficient and avoid issues with exponential growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformed Predictor vs. Log Transformed Target\n",
    "\n",
    "We are modeling the relationship as:\n",
    "\n",
    "$$ \\large{ log(y) = \\beta * log(x) \\ldots } $$\n",
    "\n",
    "For **small** values of $\\beta$ and a 1% increase, we can interpret $\\beta$ as:\n",
    "\n",
    "> For each increase of $\\large{1\\%}$ in $\\large{x}$, we see an associated change of $\\large{\\beta\\%}$ in $\\large{y}$\n",
    "\n",
    "For **larger** values of $\\beta$ and/or percentages larger than 1%, we can also use this formula:\n",
    "\n",
    "> For each increase of $\\large{p\\%}$ in $\\large{x}$, we see an associated change of $\\large{((e^{\\beta * log((100 + p)/100)} - 1) * 100)\\%}$ in $\\large{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, you got a quick review of the math background for logarithmic functions, and saw how they can be used to transform both predictors and targets in linear regression models. Interpreting the resulting coefficients can be much more complicated than interpreting basic linear regression coefficients, so we walked through all of formulas you can use. Remember that log transformations are non-linear transformations, so they should only be used if you have a reason to believe that the underlying relationship is not linear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
